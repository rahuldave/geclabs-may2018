{
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3", 
      "name": "python3", 
      "language": "python"
    }, 
    "language_info": {
      "mimetype": "text/x-python", 
      "nbconvert_exporter": "python", 
      "name": "python", 
      "file_extension": ".py", 
      "version": "3.6.1", 
      "pygments_lexer": "ipython3", 
      "codemirror_mode": {
        "version": 3, 
        "name": "ipython"
      }
    }, 
    "anaconda-cloud": {}, 
    "name": "_merged"
  }, 
  "nbformat": 4, 
  "nbformat_minor": 2, 
  "cells": [
    {
      "source": [
        "#  Regression (kNN and Linear) against a single feature"
      ], 
      "cell_type": "markdown", 
      "metadata": {}
    }, 
    {
      "execution_count": 1, 
      "cell_type": "code", 
      "source": [
        "# The %... is an iPython thing, and is not part of the Python language.\n", 
        "# In this case we're just telling the plotting library to draw things on\n", 
        "# the notebook, instead of on a separate window.\n", 
        "%matplotlib inline \n", 
        "#this line above prepares IPython notebook for working with matplotlib\n", 
        "\n", 
        "# See all the \"as ...\" contructs? They're just aliasing the package names.\n", 
        "# That way we can call methods like plt.plot() instead of matplotlib.pyplot.plot().\n", 
        "\n", 
        "import numpy as np # imports a fast numerical programming library\n", 
        "import scipy as sp #imports stats functions, amongst other things\n", 
        "import matplotlib as mpl # this actually imports matplotlib\n", 
        "import matplotlib.cm as cm #allows us easy access to colormaps\n", 
        "import matplotlib.pyplot as plt #sets up plotting under plt\n", 
        "import pandas as pd #lets us handle data as dataframes\n", 
        "#sets up pandas table display\n", 
        "pd.set_option('display.width', 500)\n", 
        "pd.set_option('display.max_columns', 100)\n", 
        "pd.set_option('display.notebook_repr_html', True)\n", 
        "import seaborn.apionly as sns #sets up styles and gives us more plotting options"
      ], 
      "outputs": [], 
      "metadata": {
        "collapsed": true
      }
    }, 
    {
      "execution_count": 2, 
      "cell_type": "code", 
      "source": [
        "dfcars=pd.read_csv(\"data/mtcars-cleaned.csv\")\n", 
        "dfcars.head()"
      ], 
      "outputs": [], 
      "metadata": {}
    }, 
    {
      "source": [
        "## Numpy indexing and the train-test split"
      ], 
      "cell_type": "markdown", 
      "metadata": {}
    }, 
    {
      "source": [
        "We can use range to construct an object which represents the list of numbers between 0 and some N. This is done as `range(N)`."
      ], 
      "cell_type": "markdown", 
      "metadata": {}
    }, 
    {
      "execution_count": 3, 
      "cell_type": "code", 
      "source": [
        "length_dataframe = dfcars.shape[0]\n", 
        "range(length_dataframe)"
      ], 
      "outputs": [], 
      "metadata": {}
    }, 
    {
      "source": [
        "The range can be materialized by running the `list` constructor over it. Why do it this way? Suppose you wanted range(million). You dont want to store million numbers in memory when you can always generate the next one by adding 1 to the previous one:"
      ], 
      "cell_type": "markdown", 
      "metadata": {}
    }, 
    {
      "execution_count": 4, 
      "cell_type": "code", 
      "source": [
        "list(range(length_dataframe))"
      ], 
      "outputs": [], 
      "metadata": {}
    }, 
    {
      "source": [
        "Lets use `range` in the construction of training and test sets. Recall that we split our data into training and test sets so that we can evaluate our model on the test set. The diagram below illustrates a situation in which we split our dataset 80% training, with the remaining 20% testing.\n", 
        "\n", 
        "![](images/train-test.png)\n", 
        "\n", 
        "Our general strategy is to do this randomly. `sklearn` gives us an easy to use function for this purpose. Notice that we split the range, which then leads to a materialization into lists of indices"
      ], 
      "cell_type": "markdown", 
      "metadata": {}
    }, 
    {
      "execution_count": 5, 
      "cell_type": "code", 
      "source": [
        "from sklearn.model_selection import train_test_split\n", 
        "split = train_test_split(range(length_dataframe), train_size=0.8)"
      ], 
      "outputs": [], 
      "metadata": {
        "collapsed": true
      }
    }, 
    {
      "execution_count": 6, 
      "cell_type": "code", 
      "source": [
        "split"
      ], 
      "outputs": [], 
      "metadata": {}
    }, 
    {
      "source": [
        "Lets assign index lists to each member of the split:"
      ], 
      "cell_type": "markdown", 
      "metadata": {}
    }, 
    {
      "execution_count": 7, 
      "cell_type": "code", 
      "source": [
        "i_train, i_test = split\n", 
        "i_train"
      ], 
      "outputs": [], 
      "metadata": {}
    }, 
    {
      "source": [
        "In another way of picking certain \"rows\" from a dataframe, we can use this list of indices to pick up a bunch or car weights for the training set"
      ], 
      "cell_type": "markdown", 
      "metadata": {}
    }, 
    {
      "execution_count": 8, 
      "cell_type": "code", 
      "source": [
        "dfcars.wt[i_train]"
      ], 
      "outputs": [], 
      "metadata": {}
    }, 
    {
      "source": [
        "Notice that this does not work for the entire dataframe!"
      ], 
      "cell_type": "markdown", 
      "metadata": {}
    }, 
    {
      "execution_count": 9, 
      "cell_type": "code", 
      "source": [
        "dfcars[i_train]"
      ], 
      "outputs": [], 
      "metadata": {}
    }, 
    {
      "source": [
        "This is because the fundamental model in indexing dataframes refers to coluns, not rows. To make this work in dataframes we use `iloc`"
      ], 
      "cell_type": "markdown", 
      "metadata": {}
    }, 
    {
      "execution_count": 10, 
      "cell_type": "code", 
      "source": [
        "dfcars.iloc[i_train]"
      ], 
      "outputs": [], 
      "metadata": {
        "scrolled": true
      }
    }, 
    {
      "source": [
        "## Creating features for regression\n", 
        "\n", 
        "Our next job is to create the weight feature training set for our regression. We can use the Pandas series or the corresponding numpy array. The example below uses the numpy array"
      ], 
      "cell_type": "markdown", 
      "metadata": {}
    }, 
    {
      "execution_count": 12, 
      "cell_type": "code", 
      "source": [
        "xtrain = dfcars.wt.values[i_train]\n", 
        "xtrain"
      ], 
      "outputs": [], 
      "metadata": {}
    }, 
    {
      "source": [
        "> YOUR TURN NOW\n", 
        "\n", 
        ">Create the test set of car weights in the variable `xtest`."
      ], 
      "cell_type": "markdown", 
      "metadata": {}
    }, 
    {
      "execution_count": 13, 
      "cell_type": "code", 
      "source": [
        "# your code here\n"
      ], 
      "outputs": [], 
      "metadata": {}
    }, 
    {
      "execution_count": 14, 
      "cell_type": "code", 
      "source": [
        "ytrain = dfcars.mpg.values[i_train]\n", 
        "ytest = dfcars.mpg.values[i_test]"
      ], 
      "outputs": [], 
      "metadata": {
        "collapsed": true
      }
    }, 
    {
      "source": [
        "## The shape of things in scikit-learn\n", 
        "\n", 
        "Scikit-learn is the main python machine learning library. It consists of many learners which can learn models from data, as well as a lot of utility functions such as train_test_split. It can be used in python by the incantation import sklearn.\n", 
        "\n", 
        "The library has a very well defined interface. This makes the library a joy to use, and surely contributes to its popularity. As the scikit-learn API paper [Buitinck, Lars, et al. \"API design for machine learning software: experiences from the scikit-learn project.\" arXiv preprint arXiv:1309.0238 (2013).] says:\n", 
        "\n", 
        ">All objects within scikit-learn share a uniform common basic API consisting of three complementary interfaces: an estimator interface for building and \ufb01tting models, a predictor interface for making predictions and a transformer interface for converting data. The estimator interface is at the core of the library. It de\ufb01nes instantiation mechanisms of objects and exposes a fit method for learning a model from training data. All supervised and unsupervised learning algorithms (e.g., for classi\ufb01cation, regression or clustering) are o\ufb00ered as objects implementing this interface. Machine learning tasks like feature extraction, feature selection or dimensionality reduction are also provided as estimators.\n", 
        "\n", 
        "\n", 
        "Lets see the structure of scikit-learn needed to make these fits. `.fit` always takes two arguments:\n", 
        "\n", 
        "`estimator.fit(Xtrain, ytrain)`.\n", 
        "\n", 
        "Critically, `Xtrain` must be in the form of an array of arrays, with the inner array each corresponding to one sample, and whose elements correspond to the feature values for that sample. \n", 
        "\n", 
        "The `ytrain` on the other hand is a simple array of responses..continuous for regression problems.\n", 
        "\n", 
        "\n"
      ], 
      "cell_type": "markdown", 
      "metadata": {}
    }, 
    {
      "source": [
        "![](images/sklearn2.jpg)"
      ], 
      "cell_type": "markdown", 
      "metadata": {}
    }, 
    {
      "source": [
        "Let us see what our shapes look like:"
      ], 
      "cell_type": "markdown", 
      "metadata": {}
    }, 
    {
      "execution_count": 15, 
      "cell_type": "code", 
      "source": [
        "xtrain.shape"
      ], 
      "outputs": [], 
      "metadata": {}
    }, 
    {
      "source": [
        "This is not what we want. We have 25 samples, but we want the data to look like a list of 25 feature vextors (each of size 1 here). So we must *reshape*."
      ], 
      "cell_type": "markdown", 
      "metadata": {}
    }, 
    {
      "execution_count": 16, 
      "cell_type": "code", 
      "source": [
        "Xtrain = xtrain.reshape(xtrain.shape[0], 1)\n", 
        "Xtrain"
      ], 
      "outputs": [], 
      "metadata": {}
    }, 
    {
      "execution_count": 17, 
      "cell_type": "code", 
      "source": [
        "Xtrain.shape"
      ], 
      "outputs": [], 
      "metadata": {}
    }, 
    {
      "source": [
        "Notice our notation: we started with the vector `xtrain`, a vectore of length 25 (shape (25,)) and comstructed a **design matrix**   `Xtrain` of size 25 x 1. We use CAPS for the first letter to remind ourselves of this."
      ], 
      "cell_type": "markdown", 
      "metadata": {}
    }, 
    {
      "execution_count": 18, 
      "cell_type": "code", 
      "source": [
        "ytrain.shape"
      ], 
      "outputs": [], 
      "metadata": {}
    }, 
    {
      "source": [
        "`ytrain` is expected to be a vector. \n", 
        "\n", 
        "> YOUR TURN NOW\n", 
        "\n", 
        "> Let us also reshape `xtest` into `Xtest`"
      ], 
      "cell_type": "markdown", 
      "metadata": {}
    }, 
    {
      "execution_count": 19, 
      "cell_type": "code", 
      "source": [
        "# your code here\n"
      ], 
      "outputs": [], 
      "metadata": {
        "collapsed": true
      }
    }, 
    {
      "source": [
        "### Regress"
      ], 
      "cell_type": "markdown", 
      "metadata": {}
    }, 
    {
      "execution_count": 20, 
      "cell_type": "code", 
      "source": [
        "#import linear model\n", 
        "from sklearn.linear_model import LinearRegression\n", 
        "from sklearn.metrics import mean_squared_error\n", 
        "\n", 
        "#create linear model\n", 
        "regression = LinearRegression()\n", 
        "\n", 
        "#fit linear model\n", 
        "regression.fit(Xtrain, ytrain)"
      ], 
      "outputs": [], 
      "metadata": {}
    }, 
    {
      "source": [
        "At this point we have fit our model using the `fit` API method in sklearn. Now comes the next critical method, `predict`. The test set `Xtest` has the same structure as `Xtrain`, and is used in the `.predict` interface. Once we have fit the estimator, we predict the results on the test set by:\n", 
        "\n", 
        "`estimator.predict(Xtest)`.\n", 
        "\n", 
        "The results of this are a simple array of predictions, of the same form and shape as `ytest`."
      ], 
      "cell_type": "markdown", 
      "metadata": {}
    }, 
    {
      "execution_count": 21, 
      "cell_type": "code", 
      "source": [
        "#predict y-values\n", 
        "predicted_y = regression.predict(Xtest)"
      ], 
      "outputs": [], 
      "metadata": {
        "collapsed": true
      }
    }, 
    {
      "source": [
        "sklearn will now provide you with a default way to score your model, which for regression problems is $R^2$"
      ], 
      "cell_type": "markdown", 
      "metadata": {}
    }, 
    {
      "execution_count": 22, 
      "cell_type": "code", 
      "source": [
        "#score predictions (sklearn gives you R^2 as well)\n", 
        "r2 = regression.score(Xtest, ytest)\n", 
        "r2"
      ], 
      "outputs": [], 
      "metadata": {}
    }, 
    {
      "source": [
        "> YOUR TURN NOW\n", 
        "\n", 
        "> Dind the $R^2$ on the training set. Is it better or worse?"
      ], 
      "cell_type": "markdown", 
      "metadata": {}
    }, 
    {
      "execution_count": 23, 
      "cell_type": "code", 
      "source": [
        "#your turn now\n", 
        "regression.score(Xtrain, ytrain)"
      ], 
      "outputs": [], 
      "metadata": {}
    }, 
    {
      "source": [
        "We can also access the mean squared error:"
      ], 
      "cell_type": "markdown", 
      "metadata": {}
    }, 
    {
      "execution_count": 24, 
      "cell_type": "code", 
      "source": [
        "mean_squared_error(predicted_y, ytest)"
      ], 
      "outputs": [], 
      "metadata": {}
    }, 
    {
      "source": [
        "> YOUR TURN NOW\n", 
        "\n", 
        ">Plot the predicted y against the actual y to see how we did. Ideally we'd want to be on the 45 degree line between predicted y ans actual y. In general we'll want the test set data to be distributed around this line"
      ], 
      "cell_type": "markdown", 
      "metadata": {}
    }, 
    {
      "execution_count": 25, 
      "cell_type": "code", 
      "source": [
        "# your code here\n"
      ], 
      "outputs": [], 
      "metadata": {}
    }, 
    {
      "source": [
        "We can also predict the results on a grid of x's to draw the regression line. This is akin to treating the grid like a test set, but not quite, because the grid may contain points from the training set."
      ], 
      "cell_type": "markdown", 
      "metadata": {}
    }, 
    {
      "execution_count": 26, 
      "cell_type": "code", 
      "source": [
        "plt.plot(dfcars.wt, dfcars.mpg, 'o')\n", 
        "xgrid = np.linspace(np.min(dfcars.wt), np.max(dfcars.wt), 100)\n", 
        "plt.plot(xgrid, regression.predict(xgrid.reshape(100, 1)));"
      ], 
      "outputs": [], 
      "metadata": {}
    }, 
    {
      "source": [
        "## Nearest Neighbor regression\n", 
        "\n", 
        "Now that we know the sklearn API, lets repeat the above for nearest neighbor regression with 5 neighbors"
      ], 
      "cell_type": "markdown", 
      "metadata": {}
    }, 
    {
      "execution_count": 27, 
      "cell_type": "code", 
      "source": [
        "from sklearn.neighbors import KNeighborsRegressor\n", 
        "knnreg = KNeighborsRegressor(n_neighbors=5)"
      ], 
      "outputs": [], 
      "metadata": {
        "collapsed": true
      }
    }, 
    {
      "execution_count": 28, 
      "cell_type": "code", 
      "source": [
        "knnreg.fit(Xtrain, ytrain)\n", 
        "r2 = knnreg.score(Xtest, ytest)\n", 
        "r2"
      ], 
      "outputs": [], 
      "metadata": {}
    }, 
    {
      "source": [
        "> YOUR TURN NOW\n", 
        "\n", 
        "> How do we do on the training set?"
      ], 
      "cell_type": "markdown", 
      "metadata": {}
    }, 
    {
      "execution_count": 29, 
      "cell_type": "code", 
      "source": [
        "# your code here\n"
      ], 
      "outputs": [], 
      "metadata": {}
    }, 
    {
      "source": [
        "Lets vary the number of neighbors and see what we get"
      ], 
      "cell_type": "markdown", 
      "metadata": {}
    }, 
    {
      "execution_count": 30, 
      "cell_type": "code", 
      "source": [
        "regdict = {}\n", 
        "for k in [1, 2, 4, 6, 8, 10, 15]:\n", 
        "    knnreg = KNeighborsRegressor(n_neighbors=k)\n", 
        "    knnreg.fit(Xtrain, ytrain)\n", 
        "    regdict[k] = knnreg"
      ], 
      "outputs": [], 
      "metadata": {
        "collapsed": true
      }
    }, 
    {
      "execution_count": 31, 
      "cell_type": "code", 
      "source": [
        "with sns.plotting_context('poster'):\n", 
        "    plt.plot(dfcars.wt, dfcars.mpg, 'o', label=\"data\")\n", 
        "    xgrid = np.linspace(np.min(dfcars.wt), np.max(dfcars.wt), 100)\n", 
        "    for k in [1, 2, 6,  10, 15]:\n", 
        "        predictions = regdict[k].predict(xgrid.reshape(100,1))\n", 
        "        if k in [1, 6, 15]:\n", 
        "            plt.plot(xgrid, predictions, label=\"{}nn\".format(k))\n", 
        "    plt.legend();"
      ], 
      "outputs": [], 
      "metadata": {}
    }, 
    {
      "source": [
        "Notice how the 1NN goes through every point on the training set but utterly fails elsewhere. Lets look at the scores on the training set"
      ], 
      "cell_type": "markdown", 
      "metadata": {}
    }, 
    {
      "execution_count": 65, 
      "cell_type": "code", 
      "source": [
        "ks = range(1, 15)\n", 
        "scores_train = []\n", 
        "for k in ks:\n", 
        "    knnreg = KNeighborsRegressor(n_neighbors=k)\n", 
        "    knnreg.fit(Xtrain, ytrain)\n", 
        "    score_train = knnreg.score(Xtrain, ytrain)\n", 
        "    scores_train.append(score_train)\n", 
        "plt.plot(ks, scores_train,'o-');"
      ], 
      "outputs": [], 
      "metadata": {}
    }, 
    {
      "source": [
        "Why do we get a perfect $R^2$ at k=1?"
      ], 
      "cell_type": "markdown", 
      "metadata": {}
    }, 
    {
      "source": [
        "> YOUR TURN NOW\n", 
        "\n", 
        "> Make the same plot on the test set:"
      ], 
      "cell_type": "markdown", 
      "metadata": {}
    }, 
    {
      "execution_count": 66, 
      "cell_type": "code", 
      "source": [
        "# your code here\n"
      ], 
      "outputs": [], 
      "metadata": {}
    }, 
    {
      "source": [
        "What is the best k?"
      ], 
      "cell_type": "markdown", 
      "metadata": {}
    }
  ]
}