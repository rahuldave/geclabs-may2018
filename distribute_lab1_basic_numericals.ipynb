{
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3", 
      "name": "python3", 
      "language": "python"
    }, 
    "language_info": {
      "mimetype": "text/x-python", 
      "nbconvert_exporter": "python", 
      "name": "python", 
      "file_extension": ".py", 
      "version": "3.6.1", 
      "pygments_lexer": "ipython3", 
      "codemirror_mode": {
        "version": 3, 
        "name": "ipython"
      }
    }, 
    "anaconda-cloud": {}, 
    "name": "_merged"
  }, 
  "nbformat": 4, 
  "nbformat_minor": 2, 
  "cells": [
    {
      "source": [
        "#  An intro to the Python numerical stack"
      ], 
      "cell_type": "markdown", 
      "metadata": {}
    }, 
    {
      "execution_count": 1, 
      "cell_type": "code", 
      "source": [
        "# The %... is an iPython thing, and is not part of the Python language.\n", 
        "# In this case we're just telling the plotting library to draw things on\n", 
        "# the notebook, instead of on a separate window.\n", 
        "%matplotlib inline \n", 
        "#this line above prepares IPython notebook for working with matplotlib\n", 
        "\n", 
        "# See all the \"as ...\" contructs? They're just aliasing the package names.\n", 
        "# That way we can call methods like plt.plot() instead of matplotlib.pyplot.plot().\n", 
        "\n", 
        "import numpy as np # imports a fast numerical programming library\n", 
        "import scipy as sp #imports stats functions, amongst other things\n", 
        "import matplotlib as mpl # this actually imports matplotlib\n", 
        "import matplotlib.cm as cm # allows us easy access to colormaps\n", 
        "import matplotlib.pyplot as plt #sets up plotting under plt\n", 
        "import pandas as pd #lets us handle data as dataframes\n", 
        "#sets up pandas table display\n", 
        "pd.set_option('display.width', 500)\n", 
        "pd.set_option('display.max_columns', 100)\n", 
        "pd.set_option('display.notebook_repr_html', True)\n", 
        "import seaborn.apionly as sns #sets up styles and gives us more plotting options"
      ], 
      "outputs": [], 
      "metadata": {
        "collapsed": true
      }
    }, 
    {
      "source": [
        "## Pandas \n", 
        "\n", 
        "Here is a cheatsheet for Pandas you night find useful: https://drive.google.com/folderview?id=0ByIrJAE4KMTtaGhRcXkxNHhmY2M&usp=sharing\n", 
        "\n", 
        "TODO: copy 5 commands docs from cheatsheat\n", 
        "\n", 
        "### Reading data in from a file\n", 
        "\n", 
        "A lots of the data out there in the world is in CSV files. If not, it can be put into a csv file unless its too big. If its too big, its probably  in a database where it looks like a CSV file.\n", 
        "\n", 
        "What so we mean  when we say that it looks like a CSV file? We mean that its **rectangular**, that is there  are some features/variables/co-variates of the data in columns, with observations in rows. These observations constitute a **sample** of the data, where we generally assume that the sample is drawn from the entire universe of possible observations of this type.\n", 
        "\n", 
        "Here we read in some car data (from R) from a CSV file. Note that CSV files can be output by any spreadsheet software, and are plain text, so make a great way to share data. \n", 
        "\n", 
        "The documentation for this data is [here](https://stat.ethz.ch/R-manual/R-devel/library/datasets/html/mtcars.html) but I have extracted some relevant parts below:\n", 
        "\n", 
        "```\n", 
        "Description\n", 
        "\n", 
        "The data was extracted from the 1974 Motor Trend US magazine, and comprises fuel consumption and 10 aspects of automobile design and performance for 32 automobiles (1973\u201374 models).\n", 
        "\n", 
        "Usage\n", 
        "\n", 
        "mtcars\n", 
        "Format\n", 
        "\n", 
        "A data frame with 32 observations on 11 variables.\n", 
        "\n", 
        "[, 1]\tmpg\tMiles/(US) gallon\n", 
        "[, 2]\tcyl\tNumber of cylinders\n", 
        "[, 3]\tdisp\tDisplacement (cu.in.)\n", 
        "[, 4]\thp\tGross horsepower\n", 
        "[, 5]\tdrat\tRear axle ratio\n", 
        "[, 6]\twt\tWeight (1000 lbs)\n", 
        "[, 7]\tqsec\t1/4 mile time\n", 
        "[, 8]\tvs\tV/S\n", 
        "[, 9]\tam\tTransmission (0 = automatic, 1 = manual)\n", 
        "[,10]\tgear\tNumber of forward gears\n", 
        "[,11]\tcarb\tNumber of carburetors\n", 
        "Source\n", 
        "\n", 
        "Henderson and Velleman (1981), Building multiple regression models interactively. Biometrics, 37, 391\u2013411.\n", 
        "```"
      ], 
      "cell_type": "markdown", 
      "metadata": {}
    }, 
    {
      "source": [
        "Let us capture this spreadsheet in **memory**. The structure we capture it in is called a pandas **dataframe**. "
      ], 
      "cell_type": "markdown", 
      "metadata": {}
    }, 
    {
      "execution_count": 2, 
      "cell_type": "code", 
      "source": [
        "dfcars=pd.read_csv(\"data/mtcars-course.csv\")\n", 
        "dfcars.head()"
      ], 
      "outputs": [], 
      "metadata": {}
    }, 
    {
      "source": [
        "Notice we have a table! A spreadsheet! And it indexed the rows (the 0,1,2,3,4...to the left in bold font)\n", 
        "\n", 
        "`dfcars`, in python parlance, is an instance of the pd.DataFrame class, created by calling the pd.read_csv function, which calls the DataFrame constructor inside of it. If you dont understand this sentence, dont worry, it will become clearer later. What you need to take away is that `dfcars` is a dataframe object, and it has methods, or functions belonging to it, which allow it to do things. For example `df.head()` is a method that shows the first 5 rows of the dataframe.\n", 
        "\n", 
        "The model for a pandas dataframe is that of a set of columns pasted together into a spreadsheet. This is slightly different from the model that you might be used to from Excel or Google Sheets, where you might make the spreadsheet a row at a time...\n", 
        "\n", 
        "![](images/pandastruct.png)\n", 
        "\n", 
        "(image stolen from the cheatsheet above)"
      ], 
      "cell_type": "markdown", 
      "metadata": {}
    }, 
    {
      "source": [
        "There is an ugly  poorly named column right here. Lets fix that."
      ], 
      "cell_type": "markdown", 
      "metadata": {}
    }, 
    {
      "execution_count": 3, 
      "cell_type": "code", 
      "source": [
        "dfcars=dfcars.rename(columns={\"Unnamed: 0\":\"name\"})\n", 
        "dfcars.head()"
      ], 
      "outputs": [], 
      "metadata": {}
    }, 
    {
      "source": [
        "Notice that we  created a new dataframe but renamed it as `dfcars`. This is because variables in python are just **bindings**: they are just aliases for a piece of memory.  The `rename` method on dataframes creates a new dataframe, and we rebind the variable `dfcars` to point to this new piece of memory. What about the old piece of memory `dfcars` pointed to? Its now  bindingless and will be destroyed by Python's garbage collector. This is how python manages memory on your computer.\n", 
        "\n", 
        "Unless youhave very limited memory on your computer, this is the recommended style of python programming. Dont create a `dfcars2`. If you have very limited memory, almost all pandas methods have a `inplace=True` option, see the `rename` docs for example.  You can then say:\n", 
        "```\n", 
        "In[3]: dfcars.rename(columns={\"Unnamed: 0\":\"name\"}, inplace=True)\n", 
        "```\n", 
        "\n", 
        "without reassigning, and the column will be updated in memory. "
      ], 
      "cell_type": "markdown", 
      "metadata": {}
    }, 
    {
      "source": [
        "### Properties of dataframes"
      ], 
      "cell_type": "markdown", 
      "metadata": {}
    }, 
    {
      "source": [
        "Here are some of the properties of our dataframe. The `shape` tells us the `rows x columns` we have."
      ], 
      "cell_type": "markdown", 
      "metadata": {}
    }, 
    {
      "execution_count": 4, 
      "cell_type": "code", 
      "source": [
        "dfcars.shape # 12 columns, each of length 32"
      ], 
      "outputs": [], 
      "metadata": {}
    }, 
    {
      "source": [
        "The columns may also be obtained as an attribute:"
      ], 
      "cell_type": "markdown", 
      "metadata": {}
    }, 
    {
      "execution_count": 5, 
      "cell_type": "code", 
      "source": [
        "dfcars.columns"
      ], 
      "outputs": [], 
      "metadata": {}
    }, 
    {
      "source": [
        "### Types of the columns\n", 
        "\n", 
        "Columns in a dataframe come with their own types. Some data may be categorical..they come  with only few well defined values. An example is cylinders  (`cyl`). Cars may be 4, 6, or 8 cylindered. There is a ordered interpretation to this  (8 cylinders more powerful engine) but also a one-of-three-types interpretation to this. \n", 
        "\n", 
        "Sometimes categorical data does not have an ordered interpretation. An example is `am`: a boolean variable which indicates whether the car is an automatic or not.\n", 
        "\n", 
        "Other column types ate integer, floating-point, and `object`. The latter is a catchall for anything Pandas could not infer, or a string.\n", 
        " \n", 
        "Lets see the types of the columns..."
      ], 
      "cell_type": "markdown", 
      "metadata": {}
    }, 
    {
      "execution_count": 15, 
      "cell_type": "code", 
      "source": [
        "dfcars.info()"
      ], 
      "outputs": [], 
      "metadata": {}
    }, 
    {
      "execution_count": 6, 
      "cell_type": "code", 
      "source": [
        "dfcars.dtypes"
      ], 
      "outputs": [], 
      "metadata": {}
    }, 
    {
      "source": [
        "The `dtypes` attribute tells us what kind of columns we have. Some are floating-point numbers, and these typically have continuous values. The other which are integers  have integer values like 2 carbouretters, but you could consider these as **categorical or factor variables** as well: a number of carbouretters factor. `am` is a factor coded as an integer where 0 is automatic and 1 is manual. TODO: categoricals\n", 
        "\n", 
        "`dtypes` are useful for debugging. If one of these columns is not the type you expect, it can point to missing or malformed values and you ought to go investigating. Pandas assigns these types by inspection of some of the values, and if the types are mixed it will make this an `object`, like the `name` column. This process is called **type inference**.\n", 
        "\n", 
        "Conside an example:"
      ], 
      "cell_type": "markdown", 
      "metadata": {}
    }, 
    {
      "execution_count": 7, 
      "cell_type": "code", 
      "source": [
        "different_values = ['a', 1, 2, 3]\n", 
        "different_series = pd.Series(different_values)\n", 
        "different_series"
      ], 
      "outputs": [], 
      "metadata": {}
    }, 
    {
      "execution_count": 8, 
      "cell_type": "code", 
      "source": [
        "different_series.dtypes # object because type inference fails"
      ], 
      "outputs": [], 
      "metadata": {}
    }, 
    {
      "execution_count": 9, 
      "cell_type": "code", 
      "source": [
        "similar_values = [2, 3, 4]\n", 
        "similar_series = pd.Series(similar_values)\n", 
        "similar_series"
      ], 
      "outputs": [], 
      "metadata": {}
    }, 
    {
      "execution_count": 10, 
      "cell_type": "code", 
      "source": [
        "similar_series.dtypes # correctly infers ints"
      ], 
      "outputs": [], 
      "metadata": {
        "scrolled": true
      }
    }, 
    {
      "execution_count": 11, 
      "cell_type": "code", 
      "source": [
        "trans_map = dict(M=0, A=1)\n", 
        "dfcars['am'] = dfcars['am'].apply(lambda x: trans_map[x])\n", 
        "dfcars.head()"
      ], 
      "outputs": [], 
      "metadata": {}
    }, 
    {
      "execution_count": 12, 
      "cell_type": "code", 
      "source": [
        "dfcars.dtypes"
      ], 
      "outputs": [], 
      "metadata": {}
    }, 
    {
      "source": [
        "### Saving\n", 
        "\n", 
        "Lets save this out:"
      ], 
      "cell_type": "markdown", 
      "metadata": {}
    }, 
    {
      "execution_count": 13, 
      "cell_type": "code", 
      "source": [
        "dfcars.to_csv(\"data/mtcars-cleaned.csv\", index=False)"
      ], 
      "outputs": [], 
      "metadata": {
        "collapsed": true
      }
    }, 
    {
      "source": [
        "Pandas `describe` gives us a nice statistical summary, in its own dataframe:"
      ], 
      "cell_type": "markdown", 
      "metadata": {}
    }, 
    {
      "execution_count": 14, 
      "cell_type": "code", 
      "source": [
        "dfcars.describe()"
      ], 
      "outputs": [], 
      "metadata": {}
    }, 
    {
      "source": [
        "### Accessing columns\n", 
        "\n", 
        "Like in a dictionary, we can get each column. The type of the resulting column is a Pandas **Series**. Indeed a dataframe is formed by pasting together many series. "
      ], 
      "cell_type": "markdown", 
      "metadata": {}
    }, 
    {
      "execution_count": 16, 
      "cell_type": "code", 
      "source": [
        "type(dfcars['carb'])"
      ], 
      "outputs": [], 
      "metadata": {}
    }, 
    {
      "execution_count": 17, 
      "cell_type": "code", 
      "source": [
        "dfcars['carb'] #you can also use df.carb (wont work for column names with spaces)"
      ], 
      "outputs": [], 
      "metadata": {}
    }, 
    {
      "source": [
        "One may also access columns using a \"property\" like notation, but clearly this wont fork for clumn names that have spaces in them."
      ], 
      "cell_type": "markdown", 
      "metadata": {}
    }, 
    {
      "execution_count": 18, 
      "cell_type": "code", 
      "source": [
        "dfcars.carb"
      ], 
      "outputs": [], 
      "metadata": {
        "scrolled": true
      }
    }, 
    {
      "source": [
        "## Pandas is built on top of numpy\n", 
        "\n", 
        "`numpy` is Python's numerical programming library. It provides arrays in multiple dimensions, and operations that work on these arrays. You ought to use `numpy` for scientific programming, regular python lists are just too slow.\n", 
        "\n", 
        "You can get the numpy arrays corresponding to pandas series and dataframes using the values attribute."
      ], 
      "cell_type": "markdown", 
      "metadata": {}
    }, 
    {
      "execution_count": 19, 
      "cell_type": "code", 
      "source": [
        "dfcars['carb'].values"
      ], 
      "outputs": [], 
      "metadata": {}
    }, 
    {
      "source": [
        "`dtypes` work for these as well"
      ], 
      "cell_type": "markdown", 
      "metadata": {}
    }, 
    {
      "execution_count": 20, 
      "cell_type": "code", 
      "source": [
        "dfcars['carb'].values.dtype"
      ], 
      "outputs": [], 
      "metadata": {}
    }, 
    {
      "source": [
        "You can construct numpy arrays yourself"
      ], 
      "cell_type": "markdown", 
      "metadata": {}
    }, 
    {
      "execution_count": 21, 
      "cell_type": "code", 
      "source": [
        "my_array = np.array([1,2,3], dtype=\"int64\")\n", 
        "my_array"
      ], 
      "outputs": [], 
      "metadata": {}
    }, 
    {
      "execution_count": 22, 
      "cell_type": "code", 
      "source": [
        "my_array = np.array([1,2,3,4,5], dtype=\"float64\")\n", 
        "my_array"
      ], 
      "outputs": [], 
      "metadata": {}
    }, 
    {
      "source": [
        "> YOUR TURN NOW\n", 
        "\n", 
        ">Create an array of 10 random numbers from the Normal distribution with 0 mean and standard deviation 1"
      ], 
      "cell_type": "markdown", 
      "metadata": {}
    }, 
    {
      "execution_count": null, 
      "cell_type": "code", 
      "source": [
        "# your code here\n"
      ], 
      "outputs": [], 
      "metadata": {
        "collapsed": true
      }
    }, 
    {
      "source": [
        "## Visualizing your data\n", 
        "\n", 
        "You can first see what color palette you are using. If you make multiple curves in a plot, these are the colors that will be sequentially used."
      ], 
      "cell_type": "markdown", 
      "metadata": {}
    }, 
    {
      "execution_count": 23, 
      "cell_type": "code", 
      "source": [
        "color_palette = sns.color_palette()\n", 
        "color_palette"
      ], 
      "outputs": [], 
      "metadata": {}
    }, 
    {
      "source": [
        "Seaborn's `palplot` lets you visualize the colormap you are using. We are using matplotlib's default colormap, which looks like so:"
      ], 
      "cell_type": "markdown", 
      "metadata": {}
    }, 
    {
      "execution_count": 25, 
      "cell_type": "code", 
      "source": [
        "sns.palplot(color_palette)"
      ], 
      "outputs": [], 
      "metadata": {}
    }, 
    {
      "source": [
        "### Histograms\n", 
        "\n", 
        "Let us call below `.hist` method of a Pandas series. This is an example of the way Pandas makes visualization for us easy. See the Pandas Viz documentation for more details."
      ], 
      "cell_type": "markdown", 
      "metadata": {}
    }, 
    {
      "execution_count": 26, 
      "cell_type": "code", 
      "source": [
        "dfcars.mpg.hist()\n", 
        "plt.xlabel(\"mpg\");"
      ], 
      "outputs": [], 
      "metadata": {}
    }, 
    {
      "source": [
        "We can also call the `matplotlib` `hist` fuction on a pandas series (or for that matter, anything listy, like a python list or a numpy array). \n", 
        "\n", 
        "Notice that the style is different: in the image above, pandas imposed some style setttings on us. We'll learn more about plot styles as the course progresses.\n", 
        "\n", 
        "In the `hist` function  you can also change the number of bins, and the transparency of the color."
      ], 
      "cell_type": "markdown", 
      "metadata": {}
    }, 
    {
      "execution_count": 27, 
      "cell_type": "code", 
      "source": [
        "plt.hist(dfcars.mpg, bins=15, alpha=0.5);\n", 
        "plt.xlabel(\"mpg\");\n", 
        "plt.title(\"Miles per Gallon\");"
      ], 
      "outputs": [], 
      "metadata": {}
    }, 
    {
      "source": [
        "Here are the most commonly used matplotlib plotting routines.\n", 
        "\n", 
        "![](images/mpl1.png)"
      ], 
      "cell_type": "markdown", 
      "metadata": {}
    }, 
    {
      "source": [
        "\n", 
        "\n", 
        "> YOUR TURN NOW\n", 
        "\n", 
        ">Convert the \"mpg\" series can be converted to a numpy array with the `values` attribute Set x limits to be between 0 and 40. "
      ], 
      "cell_type": "markdown", 
      "metadata": {}
    }, 
    {
      "execution_count": null, 
      "cell_type": "code", 
      "source": [
        "# your code now\n", 
        "plt.hist(dfcars.mpg.values, bins=15, alpha=0.5);\n", 
        "plt.xlim(5, 40)\n", 
        "plt.xlabel(\"mpg\");\n", 
        "plt.title(\"Miles per Gallon\");"
      ], 
      "outputs": [], 
      "metadata": {
        "collapsed": true
      }
    }, 
    {
      "source": [
        "Next we will use  seaborn to change the axes style. Here we use a dark grid. (See the seaborn docs for more styles). The rest is your job.\n", 
        "\n", 
        "We also show how to label a plot and obtain a legend from the plot. A vertical line is drawn at the mean, capturing the color used in the histogram and using it again.\n", 
        "\n", 
        "One can set bins using a list, and also label the histogram.  Finally one can \"normalize\" the histogram to put the frequencies on a probability scale"
      ], 
      "cell_type": "markdown", 
      "metadata": {}
    }, 
    {
      "execution_count": 28, 
      "cell_type": "code", 
      "source": [
        "with sns.axes_style(\"darkgrid\"):\n", 
        "    color = sns.color_palette()[0]\n", 
        "    plt.hist(dfcars.mpg.values, bins=range(3, 40, 3), label=\"probability\", color=color, normed=True)\n", 
        "    plt.axvline(dfcars.mpg.mean(), 0, 1.0, color=color, label='Mean')\n", 
        "    plt.xlabel(\"mpg\")\n", 
        "    plt.ylabel(\"Counts\")\n", 
        "    plt.title(\"Cars Miles per gallon Probability Graph\")\n", 
        "    plt.legend()"
      ], 
      "outputs": [], 
      "metadata": {}
    }, 
    {
      "source": [
        "### Plotting features against other features\n", 
        "\n", 
        "Sometimes we want to see co-variation amongst our columns. A scatter-plot does this for us. "
      ], 
      "cell_type": "markdown", 
      "metadata": {}
    }, 
    {
      "execution_count": 29, 
      "cell_type": "code", 
      "source": [
        "with sns.plotting_context('poster'): #temporarily make plot large\n", 
        "    plt.scatter(dfcars.wt, dfcars.mpg)"
      ], 
      "outputs": [], 
      "metadata": {}
    }, 
    {
      "source": [
        "You can use matplotlib's `plot` instead."
      ], 
      "cell_type": "markdown", 
      "metadata": {}
    }, 
    {
      "execution_count": 30, 
      "cell_type": "code", 
      "source": [
        "plt.plot(dfcars.wt, dfcars.mpg)"
      ], 
      "outputs": [], 
      "metadata": {}
    }, 
    {
      "source": [
        "This gave us spagetti lines. Why? "
      ], 
      "cell_type": "markdown", 
      "metadata": {}
    }, 
    {
      "source": [
        "One can use markers instead of lines. Also see how the semicolon suppresses the text output like `[<matplotlib.lines.Line2D at 0x10ffbd978>]`. The semicolon will generally supress the return value of any python function."
      ], 
      "cell_type": "markdown", 
      "metadata": {}
    }, 
    {
      "execution_count": 31, 
      "cell_type": "code", 
      "source": [
        "plt.plot(dfcars.wt, dfcars.mpg, 'o');"
      ], 
      "outputs": [], 
      "metadata": {}
    }, 
    {
      "source": [
        "Usually we use `plt.show()` at the end of every plot to show the plot. Out magic incantation `%matplotlib inline` takes care of this for us, and we dont have to doit in the jupyter notebook. But if you run your puthon program from a file, you will need to explicitly have a call to show. Does not hurt us to include it"
      ], 
      "cell_type": "raw", 
      "metadata": {}
    }, 
    {
      "execution_count": 32, 
      "cell_type": "code", 
      "source": [
        "plt.plot(dfcars.wt, dfcars.mpg, 'o')\n", 
        "plt.show()"
      ], 
      "outputs": [], 
      "metadata": {}
    }, 
    {
      "source": [
        "But what if we want to save our figure into a file? The extension tells you how it will be saved..and note that the `savefig` needs to be in the same cell as the plotting commands. Go look at the files.."
      ], 
      "cell_type": "markdown", 
      "metadata": {}
    }, 
    {
      "execution_count": 33, 
      "cell_type": "code", 
      "source": [
        "plt.plot(dfcars.wt, dfcars.mpg, 'o')\n", 
        "plt.savefig('foo1.pdf')\n", 
        "plt.savefig('foo2.png', bbox_inches='tight') #less whitespace around image"
      ], 
      "outputs": [], 
      "metadata": {}
    }, 
    {
      "source": [
        "## Masks and Queries\n", 
        "\n", 
        "A dataframe is useless if you cant dice/sort/etc it. To do this, one needs to use the concept of a **boolean mask**."
      ], 
      "cell_type": "markdown", 
      "metadata": {}
    }, 
    {
      "execution_count": 34, 
      "cell_type": "code", 
      "source": [
        "dfcars.mpg < 20"
      ], 
      "outputs": [], 
      "metadata": {}
    }, 
    {
      "source": [
        "This gives us Trues and Falses. Such a series is called a **mask**.  A mask  is the basis of filtering. We can do:"
      ], 
      "cell_type": "markdown", 
      "metadata": {}
    }, 
    {
      "execution_count": 35, 
      "cell_type": "code", 
      "source": [
        "dfcars[dfcars.mpg < 20]"
      ], 
      "outputs": [], 
      "metadata": {}
    }, 
    {
      "source": [
        "Notice that the dataframe(spreadsheet) has been filtered down to only include those carws with mpg < 20. The rows with `False` in the mask have been eliminated, and those with `True` in the mask have been kept."
      ], 
      "cell_type": "markdown", 
      "metadata": {}
    }, 
    {
      "execution_count": 36, 
      "cell_type": "code", 
      "source": [
        "np.sum(dfcars.mpg < 20)"
      ], 
      "outputs": [], 
      "metadata": {}
    }, 
    {
      "source": [
        "Why did that work? The booleans are coerced to integers as below:"
      ], 
      "cell_type": "markdown", 
      "metadata": {}
    }, 
    {
      "execution_count": 37, 
      "cell_type": "code", 
      "source": [
        "1*True, 1*False"
      ], 
      "outputs": [], 
      "metadata": {}
    }, 
    {
      "source": [
        "If we count the number of Trues, and divide by the total, we'll get the fraction of  cars with mpg < 20. Thus you can get probabilities by computing sample means (since you divide by the total number of items, and those not fitting the query give 0)"
      ], 
      "cell_type": "markdown", 
      "metadata": {}
    }, 
    {
      "execution_count": 38, 
      "cell_type": "code", 
      "source": [
        "np.mean(dfcars.mpg < 20)"
      ], 
      "outputs": [], 
      "metadata": {}
    }, 
    {
      "source": [
        "Or directly, in Pandas, which works since dfcars.mpg is a pandas Series."
      ], 
      "cell_type": "markdown", 
      "metadata": {}
    }, 
    {
      "execution_count": 39, 
      "cell_type": "code", 
      "source": [
        "(dfcars.mpg < 20).mean()"
      ], 
      "outputs": [], 
      "metadata": {}
    }
  ]
}